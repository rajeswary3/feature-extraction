{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install inflect\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Nokia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import AddFunctionalities as adjF\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "import nltk\n",
    "\n",
    "#GSD Pruning\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chkIfAlreadyExistExactMatch(word,strArr):\n",
    "\n",
    "    \n",
    "    strW = strArr.split(\"|\")\n",
    "   \n",
    "    for h in range (len(strW)):\n",
    "        strWW = strW[h]\n",
    "        print(\"strWW \",strWW)\n",
    "        print ( \"word \",word)\n",
    "        wExist= \"false\"\n",
    "        if ( word == strWW):\n",
    "            print(word ,\"exist\", strWW)\n",
    "            wExist =\"true\"\n",
    "            break\n",
    "     \n",
    "    return wExist;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read freq nouns\n",
    "freqNounList=[]\n",
    "with open(\"NounSetsValuefreq.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        s = line.rstrip()  \n",
    "        s.strip('\"')\n",
    "        if (len(s)>0):\n",
    "            s= s.split(\"|\")\n",
    "            nT =s[0]\n",
    "            t= s[1]\n",
    "            tInt = int(t)\n",
    "            if (tInt>=0):\n",
    "                freqNounList.append(nT)\n",
    "file.close()\n",
    "\n",
    "def chkFreqNoun(word) :\n",
    "    exist = \"\"\n",
    "    op =\"\"\n",
    "    for a in range ( len (freqNounList)):\n",
    "        op = freqNounList[a]\n",
    "        if ( op== word):\n",
    "            exist =\"true\"\n",
    "            break\n",
    "        else:\n",
    "            exist =\"false\"   \n",
    "    return \"true\";\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrcated aspect basedon pos rule\n",
    "pos1=open(\"newrulesOut.txt\", \"r\")\n",
    "content2 = pos1.read()\n",
    "x_pred=[]\n",
    "xx= content2.split(\"\\n\")\n",
    "for z in range (len(xx)):\n",
    "     if ( len(xx[z])>0):\n",
    "        x_pred.append(xx[z])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"xpred \", len(x_pred))\n",
    "\n",
    "nVal=[]\n",
    "count = 0\n",
    "countpred = 0\n",
    "for c in range (len(x_pred)):\n",
    "    strV=\"\"\n",
    "    newS=\"\"\n",
    "    value_x = x_pred[c]\n",
    "    value_x1 = value_x.split(\":\")\n",
    "    valuexS=''\n",
    "    value_xV=''\n",
    "\n",
    "    if (len(value_x1)>0):\n",
    "        asValues = value_x1[1]\n",
    "        revId_pred =value_x1[0]\n",
    "        value_xT = asValues.split(\"|\")\n",
    "        if (len(value_xT)>0):\n",
    "            for k in range (len(value_xT)):\n",
    "                ruleVal1 = value_xT[k]\n",
    "                ruleVal=ruleVal1.split(\"#\")\n",
    "                if (len(ruleVal1)>0):\n",
    "                    for j in range (len(ruleVal)):\n",
    "                        value_xV = ruleVal[1]\n",
    "                        existT = chkIfAlreadyExistExactMatch(value_xV,strV)\n",
    "                        if (existT == \"false\"):\n",
    "                            if (len(strV)>0):\n",
    "                                strV = strV +\"|\"+value_xV\n",
    "                                count = count+1\n",
    "                            else: \n",
    "                                strV =value_xV\n",
    "                                count = count+1\n",
    "                else :\n",
    "                                       \n",
    "                    strV=\"\"\n",
    "    else:                    \n",
    "        strV=\"\"\n",
    "        revId_pred=value_x\n",
    "   \n",
    "    if (len(strV)>1):\n",
    "        newS= revId_pred+\":\"+  strV\n",
    "        nVal.append(newS)\n",
    "        countpred=countpred+1\n",
    "    else:\n",
    "        newS= revId_pred+\":\"\n",
    "        nVal.append(newS)\n",
    "\n",
    "\n",
    "data=nVal\n",
    "df = pd.DataFrame({ 'Value': data })\n",
    "np.savetxt(r'filteredPredFeatureNokiaTest.txt', df.values, fmt='%s',delimiter ='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrcated aspect basedon pos rule\n",
    "\n",
    "pos2=open(\"NokiaAspects_Explicit246.txt\", \"r\")\n",
    "content = pos2.read()\n",
    "\n",
    "\n",
    "y_act=[]\n",
    "numRev = 0\n",
    "yy= content.split(\"\\n\")\n",
    "\n",
    "for s in range (len(yy)):\n",
    "     if ( len(yy[s])>1):\n",
    "            y_act.append(yy[s])\n",
    "            numRev = numRev +1\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrcated aspect basedon pos rule\n",
    "pos3=open(\"filteredPredFeatureNokiaTest.txt\", \"r\")\n",
    "content3 = pos3.read()\n",
    "\n",
    "\n",
    "x_pred=[]\n",
    "pre =1\n",
    "xx= content3.split(\"\\n\")\n",
    "\n",
    "for s in range (len(xx)):\n",
    "    if ( len(xx[s])>1):\n",
    "        pre=1\n",
    "    x_pred.append(xx[s])\n",
    "            \n",
    "x_pred2=[]\n",
    "for u in range (len(x_pred)):\n",
    "    val= x_pred[u]\n",
    "    if (len(val)>1):\n",
    "        x_pred2.append(val)\n",
    "\n",
    "nVal = x_pred2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemme = WordNetLemmatizer()\n",
    "porterMe=PorterStemmer()\n",
    "\n",
    "actualNpredictedMatched = 0\n",
    "overpredictedNotMatched = 0\n",
    "actualfeatureNotMatched=0\n",
    "noActualNopredicted =0\n",
    "\n",
    "TNVal =[]\n",
    "TPVal = []\n",
    "FNVal =[]\n",
    "FPVal =[]\n",
    "vaD=[]\n",
    "notpredicted =0\n",
    "totalActualFeature = 0\n",
    "totalFoundFet =0\n",
    "totalNotFound =0\n",
    "ActNotfoundMatchwithPredCount = 0\n",
    "overpredCount=0\n",
    "revMatch=0\n",
    "for a in range (len(y_act)):\n",
    "\n",
    "   \n",
    "    emptyActualFeature =\"false\"\n",
    "    value_y =y_act[a]\n",
    "    value_y = value_y.split(\",\")\n",
    "\n",
    "    revId_act =value_y[0]\n",
    "    feature_act = value_y[1]\n",
    "    \n",
    "    noOfFeature_act = len(feature_act)\n",
    "\n",
    "    countX =0\n",
    "    if (noOfFeature_act >0):\n",
    "        feature_act =  feature_act.split(\"|\")\n",
    "        if (len (feature_act)>0):\n",
    "            feature_act1 = feature_act[0]\n",
    "        totalActualFeature =totalActualFeature+ len (feature_act)\n",
    "        foundMatch = \"false\"\n",
    "        matchedVal=\"\"\n",
    "        matchedValLocalCount =0\n",
    "        overpredCurrReview=0\n",
    "        for b in range (len (feature_act ))  :\n",
    "            ActNotfoundMatchwithPred=\"false\"\n",
    "            featureW = feature_act[b]\n",
    "            for c in range (len(nVal)):\n",
    "                Str1 = nVal[c]\n",
    "                Str1 = Str1.split(\":\")\n",
    "                extractFeaId = Str1[0]\n",
    "                extractFeas=\"\"\n",
    "                if (revId_act==extractFeaId):\n",
    "                    predValNotMatch=\"false\"\n",
    "                    predValNotMatchCount =0\n",
    "                    extractCount =0\n",
    "                    if ((len(Str1)>1)):\n",
    "                        extractFeas = Str1[1]\n",
    "                        extractFeas=extractFeas.strip()\n",
    "                        extractFeas = extractFeas.split(\"|\")\n",
    "                        NoOfExtractedValue = len(extractFeas)\n",
    "                        for d in range (len(extractFeas)):\n",
    "                            fet1 = extractFeas[d]\n",
    "                            if ((len(fet1))==0):\n",
    "                                foundMatch = \"false\"\n",
    "                            else:\n",
    "                                newWT = porterMe.stem(fet1)\n",
    "                                neWW=\"\"\n",
    "                                newW=newWT\n",
    "                                featureW2_1=\"\"\n",
    "                                featureW2_2=\"\"\n",
    "                                valFet2_1=\"\"\n",
    "                                valFet2_2=\"\"\n",
    "                                fet2= fet1.split(\" \")\n",
    "                                if (len(fet2)>1):\n",
    "                                    valFet2_1=fet2[0]\n",
    "                                    valFet2_2 = fet2[1]\n",
    "                                if(len(fet2)==1):\n",
    "                                    valFet2_1=fet2[0]\n",
    "                                    valFet2_2 = \"none\"\n",
    "                                       \n",
    "                                featureWW = porterMe.stem(featureW)\n",
    "                                featureW2= featureW.split (\" \")\n",
    "                                if (len(featureW2)>1):\n",
    "                                    featureW2_1=featureW2[0]\n",
    "                                    featureW2_2 = featureW2[1]\n",
    "                                    \n",
    "                                if (len(featureW2)==1):\n",
    "                                    featureW2_1=featureW2[0]\n",
    "                                    featureW2_1=\"null\"\n",
    "                                       \n",
    "                                    \n",
    "                                try:\n",
    "                                    nsim = newW+'.n.01' \n",
    "                                    nsimL =featureW+'.n.01'\n",
    "                                    cb = wordnet.synset(nsimL)\n",
    "                                    ib = wordnet.synset(nsim)\n",
    "                                    sim = cb.wup_similarity(ib)\n",
    "                                    sim = str(round(sim, 4))\n",
    "                                    \n",
    "                                except:\n",
    "                                    pass\n",
    "                            \n",
    "                                if ((fet1 ==featureW ) or(newW ==featureW )or (featureW.find(fet1)!= -1) or (fet1.find(featureW)!= -1)or (featureW.find(newW)!= -1) or (newW.find(featureW)!= -1)  or (valFet2_1==featureW2_1) or (valFet2_1==featureW2_2)or (valFet2_2==featureW2_1) or (valFet2_2==featureW2_2) )and  (chkFreqNoun(featureW)==\"true\"):\n",
    "                                    foundMatch = \"true\"\n",
    "                                    predValNotMatch=\"true\"\n",
    "                                    countX=countX+1\n",
    "                                    ActNotfoundMatchwithPred=\"true\"\n",
    "                                    matchedValLocalCount=matchedValLocalCount+1\n",
    "                                    extractCount=0\n",
    "                                    if (len(matchedVal)>0):\n",
    "                                        matchedVal = matchedVal+\"|\"+fet1\n",
    "                                    else :\n",
    "                                        matchedVal = fet1\n",
    "\n",
    "                                    actualNpredictedMatched = actualNpredictedMatched+1\n",
    "                                    valS = actualNpredictedMatched,\" # \"+extractFeaId +\" :\"+fet1\n",
    "                                    valD = extractFeaId,matchedVal\n",
    "                                    vaD.append(valD)\n",
    "                                    foundMatchwithPred =\"true\"\n",
    "                                    TPVal.append(valS)\n",
    "                                    \n",
    "                        if (ActNotfoundMatchwithPred==\"false\") and (chkFreqNoun(featureW)==\"true\"):\n",
    "                            ActNotfoundMatchwithPredCount=ActNotfoundMatchwithPredCount+1\n",
    "                            valS = revId_act +\" :\"+featureW\n",
    "                            FNVal.append(valS)\n",
    "                        \n",
    "                        overpredCurrReview = NoOfExtractedValue-matchedValLocalCount\n",
    "                       \n",
    "                    else:  #no predicted feature for this review if:\n",
    "                        foundMatch = \"false\"\n",
    "                        ActNotfoundMatchwithPredCount=ActNotfoundMatchwithPredCount+1\n",
    "               \n",
    "        overpredCount = overpredCount +overpredCurrReview\n",
    "        if (foundMatch ==\"true\"):\n",
    "            revMatch=revMatch+1    \n",
    "            \n",
    "            \n",
    "        if (foundMatch ==\"false\"):\n",
    "            v=\"\"\n",
    "            for j in range (len(feature_act)):\n",
    "                v  = v+ \",\"+ feature_act[j]\n",
    "            valS = len( feature_act) ,\" # \",revId_act +\" :\"+v\n",
    "            FNVal.append(valS)\n",
    "        \n",
    "        for c in range (len(nVal)): \n",
    "            Str1 = nVal[c]\n",
    "            Str1 = Str1.split(\":\")\n",
    "            extractFeaId = Str1[0]\n",
    "\n",
    "            if (revId_act==extractFeaId) and (noOfFeature_act>0):\n",
    "                if ((len(Str1))>1):\n",
    "                \n",
    "                    extractFeas = Str1[1]\n",
    "                    extractFeas = extractFeas.split(\"|\")\n",
    "\n",
    "                    NoOfExtractedValue = len(extractFeas)\n",
    "                    \n",
    "                    if (NoOfExtractedValue>1):\n",
    "                        newVal = NoOfExtractedValue -countX\n",
    "                        overpredictedNotMatched = overpredictedNotMatched + newVal\n",
    "                        v = \"\"\n",
    "                        for j in range(len (extractFeas)):\n",
    "                            if ((len(v))>0):\n",
    "                                v = v+ \",\"+ extractFeas[j]\n",
    "                            else:\n",
    "                                v = extractFeas[j]\n",
    "\n",
    "\n",
    "                        valS = str(newVal)+\" # \"+extractFeaId+\":\"+v+ \"----\"+matchedVal\n",
    "                        FPVal.append(valS)\n",
    "\n",
    "    else : # no actual feature recorded for this review\n",
    "        for c in range (len(nVal)):\n",
    "                Str1 = nVal[c]\n",
    "                Str1 = Str1.split(\":\")\n",
    "                extractFeaId = Str1[0]\n",
    "                if (revId_act==extractFeaId):\n",
    "                   \n",
    "                    if ((len(Str1))>1):\n",
    "                        extractFeas = Str1[1]\n",
    "                        extractedFeatureCount = len(extractFeas)\n",
    "                        if (extractedFeatureCount >0 ): # this means no actual feature but have predicted feature\n",
    "                            extractFeas = extractFeas.split(\"|\")\n",
    "                            NoOfExtractedValue = len(extractFeas)\n",
    "\n",
    "                            if (NoOfExtractedValue>0):\n",
    "                                overpredictedNotMatched =overpredictedNotMatched+NoOfExtractedValue\n",
    "                                v = \"\"\n",
    "                                for j in range (len(extractFeas)):\n",
    "                                    if ((len(v))>0):\n",
    "                                        v = v+ \",\"+ extractFeas[j]\n",
    "                                    else:\n",
    "                                        v = extractFeas[j]\n",
    "\n",
    "                                valS = str(NoOfExtractedValue)+\" # \"+extractFeaId +\" :\"+v+ \"----\"\n",
    "                                FPVal.append(valS)\n",
    "\n",
    "\n",
    "                    else: # this means no feature extracted for both actual and predicted ,which means this is a TN \n",
    "                        noActualNopredicted=noActualNopredicted+1\n",
    "                        valS = extractFeaId\n",
    "                        TNVal.append(valS)\n",
    "\n",
    "overpredicted =0\n",
    "\n",
    "for j in range (len(x_pred2)):\n",
    "    vGPred = x_pred2[j]\n",
    "    vGPred = vGPred.split(\":\")\n",
    "    predFeaId =vGPred[0]\n",
    "    predFeat  = vGPred[1]\n",
    "    predFeasG = predFeat.split(\"|\")\n",
    "    predArr = []\n",
    "    \n",
    "    for k in range (len(predFeasG)):\n",
    "        vPred = predFeasG[k]\n",
    "        predArr.append(vPred)\n",
    "    for t in range (len( predFeasG)):\n",
    "        predValue = predFeasG[t]\n",
    "        for h in range (len(vaD)):\n",
    "            ActmatchedG  =vaD[h]\n",
    "            matchdfetId = ActmatchedG[0]\n",
    "            \n",
    "            if (predFeaId == matchdfetId):\n",
    "\n",
    "                    matchedFeatures = ActmatchedG[1]\n",
    "                    matchedFeatures = matchedFeatures.split(\"|\")\n",
    "                    for y in range (len(matchedFeatures)):\n",
    "                        matchV = matchedFeatures[y]\n",
    "                        if (predValue==matchV):\n",
    "                            if (predArr.count(predValue) > 0):\n",
    "                                predArr.remove(predValue)\n",
    "    trimPredArr=[]\n",
    "    for  r in range (len(predArr )):\n",
    "        fT  = predArr[r]\n",
    "        if (chkFreqNoun(fT)==\"true\"):\n",
    "            trimPredArr.append(fT)\n",
    "    overpredicted =overpredicted+(len(trimPredArr))\n",
    "overpredictedNotMatched=overpredicted\n",
    "actualfeatureNotMatched=  ActNotfoundMatchwithPredCount\n",
    "data=TNVal\n",
    "df = pd.DataFrame({ 'Value': data })\n",
    "np.savetxt(r'NokiaTestTNValues.txt', df.values, fmt='%s',delimiter ='')\n",
    "data=TPVal\n",
    "df = pd.DataFrame({ 'Value': data })\n",
    "np.savetxt(r'NokiaTestTPValues.txt', df.values, fmt='%s',delimiter ='')\n",
    "data=FNVal\n",
    "df = pd.DataFrame({ 'Value': data })\n",
    "np.savetxt(r'NokiaTestFNValues.txt', df.values, fmt='%s',delimiter ='')\n",
    "data=FPVal\n",
    "df = pd.DataFrame({ 'Value': data })\n",
    "np.savetxt(r'NokiaTestFPValues.txt', df.values, fmt='%s',delimiter ='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TP = actualNpredictedMatched\n",
    "FN = actualfeatureNotMatched  \n",
    "TN = noActualNopredicted  \n",
    "FP = overpredictedNotMatched  \n",
    "\n",
    "\n",
    "accuracy = (TP+TN)/ ( TP+FN+TN+FP)\n",
    "precission = revMatch/countpred\n",
    "\n",
    "#print (\"Precission \", precission)\n",
    "recall = revMatch /numRev\n",
    "#print ( \"recall \", recall)\n",
    "\n",
    "fmeasure = (2*recall*precission)/(recall+precission)\n",
    "#print ( \"fmeasure \",fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
